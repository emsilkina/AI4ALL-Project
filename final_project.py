# -*- coding: utf-8 -*-
"""Final Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dIUC5J4hb0-mkkm1KsL5BDG-bCRfsz_j
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

"""Importing Datasets:"""

appleDF = pd.read_csv('/AI4ALL Project Datasets/AAPL.csv')
intelDF= pd.read_csv('/AI4ALL Project Datasets/INTC.csv')
msftDF = pd.read_csv('AI4ALL Project Datasets/MSFT.csv')
ibmDF= pd.read_csv('/AI4ALL Project Datasets/IBM.csv')
sp500DF = pd.read_csv('/AI4ALL Project Datasets/GSPC.csv')
interestRateDF = pd.read_csv('/AI4ALL Project Datasets/federalReserveInterestRates.csv')

"""# 1) Individual Stock Analysis

## AAPL Stock Breakdown

Calculating Correlations:
"""

appleDF

correlation = appleDF['Open'].corr(msftDF['Open'])
print(f'Correlation between Apple Open and Microsoft Open prices: {correlation:.4f}')

correlation = appleDF['Close'].corr(msftDF['Close'])
print(f'Correlation between Apple Close and Microsoft Close prices: {correlation:.4f}')

correlation = appleDF['Open'].corr(intelDF['Open'])
print(f'Correlation between Apple Open and Intel Open prices: {correlation:.4f}')

correlation = appleDF['Close'].corr(intelDF['Close'])
print(f'Correlation between Apple Close and Intel Close prices: {correlation:.4f}')

correlation = appleDF['Open'].corr(sp500DF['Open'])
print(f'Correlation between Apple Open and S&P500 Open prices: {correlation:.4f}')

correlation = appleDF['Close'].corr(sp500DF['Close'])
print(f'Correlation between Apple Close and S&P500 Close prices: {correlation:.4f}')

appleDF['Date'] = pd.to_datetime(appleDF['Date'])

plt.figure(figsize=(14, 6))
plt.plot(appleDF['Date'], appleDF['Close'], label='Close Price', color='blue')
plt.title('Stock Closing Price Over Time')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.tight_layout()
plt.show()

appleDF['Date'] = pd.to_datetime(appleDF['Date'])

plt.figure(figsize=(14, 6))
plt.plot(appleDF['Date'], appleDF['Open'], label='Open Price', color='blue')
plt.title('Stock Opening Price Over Time')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.tight_layout()
plt.show()

correlation = appleDF['Open'].corr(appleDF['Close'])
print(f'Correlation between Apple Open and Close prices: {correlation:.4f}')

appleDF['Date'] = pd.to_datetime(appleDF['Date'])

plt.figure(figsize=(14, 6))
plt.plot(appleDF['Date'], appleDF['Open'], label='Open Price', color='blue')
plt.plot(appleDF['Date'], appleDF['Close'], label='Close Price', color='red')
plt.title('Stock Opening and Closing Price Over Time')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.tight_layout()
plt.show()

interestRateDF=interestRateDF.interpolate()
interestRateDF['Date'] = pd.to_datetime(interestRateDF[['Year', 'Month', 'Day']])

import pandas as pd
import matplotlib.pyplot as plt

# Convert dates
appleDF['Date'] = pd.to_datetime(appleDF['Date'])
interestRateDF['Date'] = pd.to_datetime(interestRateDF[['Year', 'Month', 'Day']])

# Merge Apple and Fed Rate data
df = pd.merge(appleDF[['Date', 'Open']], interestRateDF[['Date', 'Effective Federal Funds Rate']], on='Date', how='inner')

# Rolling correlation with a 60-day window
df['RollingCorr'] = df['Open'].rolling(window=60).corr(df['Effective Federal Funds Rate'])

# Shift Fed Rate forward by 30 days (i.e., see how past Fed Rate affects future Apple stock)
df['Lagged Rate'] = df['Effective Federal Funds Rate'].shift(30)

# Drop NaNs from shifting
df_lagged = df.dropna()

# Calculate correlation
correlation = df_lagged['Open'].corr(df_lagged['Lagged Rate'])
print(f"Lagged (30-day) correlation: {correlation}")

## This is a moderate to strong negative correlation between Appleâ€™s stock price and the Federal Funds Rate from 30 days earlier.

"""## INTC Stock Breakdown"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt


intelDF= pd.read_csv('/content/drive/MyDrive/AI4ALL Project Datasets/INTC.csv')
intelDF.head() # print first 5 lines, starts at 1980
#intelDF.tail() # print last 5 lines, ends 2024

intelDF['Date']= pd.to_datetime(intelDF['Date'], utc=True) # converting to better dates

plt.figure(figsize=(14, 6)) # creating figure to plot close prices
plt.plot(intelDF['Date'], intelDF['Close'], label='Close Price', color='blue')
plt.title('Intel Stock Closing Price Over Time')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.tight_layout()
plt.show()

plt.figure(figsize=(14, 6)) # creating figure to plot open prices
plt.plot(intelDF['Date'], intelDF['Open'], label='Open Price', color='green')
plt.title('Intel Stock Opening Price Over Time')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.tight_layout()
plt.show()

plt.figure(figsize=(14, 6)) # creating figure to compare close and open prices
plt.plot(intelDF['Date'], intelDF['Open'], label='Open Price', color='green')
plt.plot(intelDF['Date'], intelDF['Close'], label='Close Price', color='blue')
plt.title('Intel Stock Opening and Closing Price Over Time')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.tight_layout()
plt.show()

interestRateDF=interestRateDF.interpolate()
interestRateDF['Date'] = pd.to_datetime(interestRateDF[['Year', 'Month', 'Day']]) # convert to better date

# plotting inflation rates
plt.figure(figsize=(14,6))
plt.plot(interestRateDF['Date'], interestRateDF['Inflation Rate'], label='Inflation Rate', color='purple')
plt.title('Inflation Rate Over Time')
plt.xlabel('Date')
plt.ylabel('Rate (%)')
plt.legend()
plt.tight_layout()
plt.show()

# Rolling Correlation of 60 days
intelDF = intelDF.sort_values('Date')
interestRateDF = interestRateDF.sort_values('Date')
intelDF['Date'] = intelDF['Date'].dt.tz_localize(None)
rollingDF2 = pd.merge_asof(intelDF[['Date', 'Open']], interestRateDF[['Date', 'Effective Federal Funds Rate']], on='Date')
rollingDF2['RollingCorr'] = rollingDF2['Open'].rolling(window=60).corr(rollingDF2['Effective Federal Funds Rate'])

plt.figure(figsize=(14,6))
plt.plot(rollingDF2['Date'], rollingDF2['RollingCorr'], color='blue')
plt.title('60-Day Rolling Correlation: Intel Open vs Fed Funds Rate')
plt.xlabel('Date')
plt.ylabel('Correlation')
plt.grid(True)
plt.tight_layout()
plt.show()

# Lagged Correlation (30 days)
rollingDF2['Lagged Rate'] = rollingDF2['Effective Federal Funds Rate'].shift(30)
rollingDF2_lagged = rollingDF2.dropna()

correlation2 = rollingDF2_lagged['Open'].corr(rollingDF2_lagged['Lagged Rate'])
print(f"Lagged (30-day) correlation: {correlation2}")

"""#### There is a moderate to strong negative correlation between Federal funds rate and Intel's stock price 30 days later. This means, when interest rates go up, Intel stocks tend to go down after about a month (and vice versa). This suggests that monetary policy decisions like rate hikes could have a delayed negative impact on Intel's stock price

### Correlating companies to each other
"""

correlation = intelDF['Open'].corr(msftDF['Open'])
print(f'Correlation between Intel Open and Microsoft Open prices: {correlation:.4f}')

correlation = intelDF['Close'].corr(msftDF['Close'])
print(f'Correlation between Intel Close and Microsoft Close prices: {correlation:.4f}')

correlation = intelDF['Open'].corr(appleDF['Open'])
print(f'Correlation between Intel Open and Apple Open prices: {correlation:.4f}')

correlation = intelDF['Close'].corr(appleDF['Close'])
print(f'Correlation between Intel Close and Apple Close prices: {correlation:.4f}')

correlation = intelDF['Open'].corr(sp500DF['Open'])
print(f'Correlation between Intel Open and S&P500 Open prices: {correlation:.4f}')

correlation = intelDF['Close'].corr(sp500DF['Close'])
print(f'Correlation between Intel Close and S&P500 Close prices: {correlation:.4f}')

"""## MSFT Stock Breakdown"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

msftDF = pd.read_csv('/content/drive/My Drive/AI4ALL Project Datasets/MSFT.csv')
msftDF.head() # starts 1986
# msftDF.tail() # ends 2025

msftDF['Date'] = pd.to_datetime(msftDF['Date'], utc=True)
plt.figure(figsize=(14,6))
plt.plot(msftDF['Date'], msftDF['Close'], label = 'Close Price', color= 'blue')
plt.title('Microsoft Stock Closing Price Over Time')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.tight_layout()
plt.show()

plt.figure(figsize=(14,6))
plt.plot(msftDF['Date'], msftDF['Open'], label= 'Open Price', color='green')
plt.title('Microsoft Stock Opening Price Over Time')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.tight_layout()
plt.show()

plt.figure(figsize=(14, 6)) # creating figure to compare close and open prices
plt.plot(msftDF['Date'], msftDF['Open'], label='Open Price', color='green')
plt.plot(msftDF['Date'], msftDF['Close'], label='Close Price', color='blue')
plt.title('Microsoft Stock Opening and Closing Price Over Time')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.tight_layout()
plt.show()

# Now comparing against economic factors
interestRateDF=interestRateDF.interpolate()
interestRateDF['Date'] = pd.to_datetime(interestRateDF[['Year', 'Month', 'Day']]) # convert to better date

# plotting unemployment rates
plt.figure(figsize=(14,6))
plt.plot(interestRateDF['Date'], interestRateDF['Unemployment Rate'], label='Unemployment Rate', color='purple')
plt.title('Unemployment Rate Over Time')
plt.xlabel('Date')
plt.ylabel('Rate (%)')
plt.legend()
plt.tight_layout()
plt.show()

# plotting inflation rates
plt.figure(figsize=(14,6))
plt.plot(interestRateDF['Date'], interestRateDF['Inflation Rate'], label='Inflation Rate', color='purple')
plt.title('Inflation Rate Over Time')
plt.xlabel('Date')
plt.ylabel('Rate (%)')
plt.legend()
plt.tight_layout()
plt.show()

# Merging and normalizing data
msftDF = msftDF.sort_values('Date')
interestRateDF = interestRateDF.sort_values('Date')

msftDF['Date'] = pd.to_datetime(msftDF['Date'])
msftDF['Date'] = msftDF['Date'].dt.tz_localize(None)

mergedDF3 = pd.merge_asof(msftDF[['Date', 'Open']], interestRateDF, on='Date')

# normalize to compare
def normalize(series):
    return (series - series.min()) / (series.max() - series.min())

mergedDF3['Open_norm'] = normalize(mergedDF3['Open'])
mergedDF3['InterestRate_norm'] = normalize(mergedDF3['Effective Federal Funds Rate'])
mergedDF3['GDP_norm'] = normalize(mergedDF3['Real GDP (Percent Change)'])
mergedDF3['Unemployment_norm'] = normalize(mergedDF3['Unemployment Rate'])
mergedDF3['Inflation_norm'] = normalize(mergedDF3['Inflation Rate'])

mergedDF3[['Date', 'Open_norm', 'InterestRate_norm', 'GDP_norm', 'Unemployment_norm', 'Inflation_norm']].head()

def normalize(series):
    return (series - series.min()) / (series.max() - series.min())

mergedDF3['Open_norm'] = normalize(mergedDF3['Open'])
mergedDF3['InterestRate_norm'] = normalize(mergedDF3['Effective Federal Funds Rate'])
mergedDF3['GDP_norm'] = normalize(mergedDF3['Real GDP (Percent Change)'])
mergedDF3['Unemployment_norm'] = normalize(mergedDF3['Unemployment Rate'])
mergedDF3['Inflation_norm'] = normalize(mergedDF3['Inflation Rate'])

# Rolling Correlation of 60 days
msftDF = msftDF.sort_values('Date')
interestRateDF = interestRateDF.sort_values('Date')
msftDF['Date'] = msftDF['Date'].dt.tz_localize(None)
rollingDF3 = pd.merge_asof(msftDF[['Date', 'Open']], interestRateDF[['Date', 'Effective Federal Funds Rate']], on='Date')
rollingDF3['RollingCorr'] = rollingDF3['Open'].rolling(window=60).corr(rollingDF3['Effective Federal Funds Rate'])

plt.figure(figsize=(14,6))
plt.plot(rollingDF3['Date'], rollingDF3['RollingCorr'], color='blue')
plt.title('60-Day Rolling Correlation: Microsoft Open vs Fed Funds Rate')
plt.xlabel('Date')
plt.ylabel('Correlation')
plt.grid(True)
plt.tight_layout()
plt.show()

# Lagged Correlation (30 days)
rollingDF3['Lagged Rate'] = rollingDF3['Effective Federal Funds Rate'].shift(30)
rollingDF3_lagged = rollingDF3.dropna()

correlation3 = rollingDF3_lagged['Open'].corr(rollingDF3_lagged['Lagged Rate'])
print(f"Lagged (30-day) correlation: {correlation3}")

"""### Correlations of other companies with Microsoft"""

correlation = msftDF['Open'].corr(appleDF['Open'])
print(f'Correlation between Microsoft Open and Apple Open prices: {correlation:.4f}')

correlation = msftDF['Close'].corr(appleDF['Close'])
print(f'Correlation between Microsoft Close and Apple Close prices: {correlation:.4f}')

correlation = msftDF['Open'].corr(intelDF['Open'])
print(f'Correlation between Microsoft Open and Intel Open prices: {correlation:.4f}')

correlation = msftDF['Close'].corr(intelDF['Close'])
print(f'Correlation between Microsoft Close and Intel Close prices: {correlation:.4f}')

correlation = msftDF['Open'].corr(sp500DF['Open'])
print(f'Correlation between Microsoft Open and S&P500 Open prices: {correlation:.4f}')

correlation = msftDF['Close'].corr(sp500DF['Close'])
print(f'Correlation between Microsoft Close and S&P500 Close prices: {correlation:.4f}')

"""## IBM Stock Breakdown"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

ibmDF = pd.read_csv('/content/drive/My Drive/AI4ALL Project Datasets/IBM.csv')
ibmDF.head() # starts 1962
# ibmDF.tail() # ends 2024

ibmDF['Date'] = pd.to_datetime(ibmDF['Date'], utc=True)
plt.figure(figsize=(14,6))
plt.plot(ibmDF['Date'], ibmDF['Close'], label = 'Close Price', color= 'blue')
plt.title('IBM Stock Closing Price Over Time')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.tight_layout()
plt.show()

plt.figure(figsize=(14,6))
plt.plot(ibmDF['Date'], ibmDF['Open'], label= 'Open Price', color='green')
plt.title('IBM Stock Opening Price Over Time')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.tight_layout()
plt.show()

plt.figure(figsize=(14, 6)) # creating figure to compare close and open prices
plt.plot(ibmDF['Date'], ibmDF['Open'], label='Open Price', color='green')
plt.plot(ibmDF['Date'], ibmDF['Close'], label='Close Price', color='blue')
plt.title('IBM Stock Opening and Closing Price Over Time')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.tight_layout()
plt.show()

# Now comparing against economic factors
interestRateDF=interestRateDF.interpolate()
interestRateDF['Date'] = pd.to_datetime(interestRateDF[['Year', 'Month', 'Day']]) # convert to better date

# plotting unemployment rates
plt.figure(figsize=(14,6))
plt.plot(interestRateDF['Date'], interestRateDF['Unemployment Rate'], label='Unemployment Rate', color='purple')
plt.title('Unemployment Rate Over Time')
plt.xlabel('Date')
plt.ylabel('Rate (%)')
plt.legend()
plt.tight_layout()
plt.show()

# plotting inflation rates
plt.figure(figsize=(14,6))
plt.plot(interestRateDF['Date'], interestRateDF['Inflation Rate'], label='Inflation Rate', color='purple')
plt.title('Inflation Rate Over Time')
plt.xlabel('Date')
plt.ylabel('Rate (%)')
plt.legend()
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Ensure data is sorted and datetime is clean
ibmDF = ibmDF.sort_values('Date')
interestRateDF = interestRateDF.sort_values('Date')

ibmDF['Date'] = pd.to_datetime(ibmDF['Date']).dt.tz_localize(None)

# Merge IBM stock data with macroeconomic indicators using asof
mergedDF_ibm = pd.merge_asof(ibmDF[['Date', 'Open']], interestRateDF, on='Date')

# Normalize function
def normalize(series):
    return (series - series.min()) / (series.max() - series.min())

# Normalize IBM Open price and economic indicators
mergedDF_ibm['Open_norm'] = normalize(mergedDF_ibm['Open'])
mergedDF_ibm['InterestRate_norm'] = normalize(mergedDF_ibm['Effective Federal Funds Rate'])
mergedDF_ibm['GDP_norm'] = normalize(mergedDF_ibm['Real GDP (Percent Change)'])
mergedDF_ibm['Unemployment_norm'] = normalize(mergedDF_ibm['Unemployment Rate'])
mergedDF_ibm['Inflation_norm'] = normalize(mergedDF_ibm['Inflation Rate'])

# Preview normalized data
print(mergedDF_ibm[['Date', 'Open_norm', 'InterestRate_norm', 'GDP_norm', 'Unemployment_norm', 'Inflation_norm']].head())

# Rolling 60-day correlation between IBM Open and Effective Federal Funds Rate
rollingDF_ibm = pd.merge_asof(
    ibmDF[['Date', 'Open']],
    interestRateDF[['Date', 'Effective Federal Funds Rate']],
    on='Date'
)
rollingDF_ibm['RollingCorr'] = rollingDF_ibm['Open'].rolling(window=60).corr(
    rollingDF_ibm['Effective Federal Funds Rate']
)

# Plot
plt.figure(figsize=(14, 6))
plt.plot(rollingDF_ibm['Date'], rollingDF_ibm['RollingCorr'], color='blue')
plt.title('60-Day Rolling Correlation: IBM Open vs Fed Funds Rate')
plt.xlabel('Date')
plt.ylabel('Correlation')
plt.grid(True)
plt.tight_layout()
plt.show()

# Lagged Correlation (30 days)
rollingDF_ibm['Lagged Rate'] = rollingDF_ibm['Effective Federal Funds Rate'].shift(30)
rollingDF_ibm_lagged = rollingDF_ibm.dropna()

correlation4 = rollingDF_ibm_lagged['Open'].corr(rollingDF_ibm_lagged['Lagged Rate'])
print(f"Lagged (30-day) correlation: {correlation4}")

"""### Correlations of companies with IBM"""

correlation = ibmDF['Open'].corr(appleDF['Open'])
print(f'Correlation between IBM Open and Apple Open prices: {correlation:.4f}')

correlation = ibmDF['Close'].corr(appleDF['Close'])
print(f'Correlation between IBM Close and Apple Close prices: {correlation:.4f}')

correlation = ibmDF['Open'].corr(intelDF['Open'])
print(f'Correlation between IBM Open and Intel Open prices: {correlation:.4f}')

correlation = ibmDF['Close'].corr(intelDF['Close'])
print(f'Correlation between IBM Close and Intel Close prices: {correlation:.4f}')

correlation = ibmDF['Open'].corr(sp500DF['Open'])
print(f'Correlation between IBM Open and S&P500 Open prices: {correlation:.4f}')

correlation = ibmDF['Close'].corr(sp500DF['Close'])
print(f'Correlation between IBM Close and S&P500 Close prices: {correlation:.4f}')

"""# 2) Correlation Analysis

## Comparison of Lagged (30-day) Correlations

1.   Apple (-0.6538579645233382)
2.   Intel (-0.6212596368881346)
3.   Microsoft (-0.3920560447898803)
4.   IBM (-0.3920560447898803)

### Apple has the strongest negative correlation, which could be attributed to the fact that it is a massive consumer tech company (which is highly exposed to global demand and interest-sensitive purchasing)

## Correlation of Company Stocks with S&P 500
"""

sp500DF['Date'] = pd.to_datetime(sp500DF['Date'], utc=True).dt.tz_localize(None)
sp500DF = sp500DF.sort_values('Date')

def compareToSP500(stockDF, name):
  stockDF['Date'] = pd.to_datetime(stockDF['Date'], utc=True).dt.tz_localize(None)
  stockDF = stockDF.sort_values('Date')

  # Merging with SP500
  mergedDF5 = pd.merge_asof(stockDF[['Date', 'Open']], sp500DF[['Date', 'Close']], on='Date')
  mergedDF5= mergedDF5.dropna()

  # Normalizing for comparison
  def normalize(series):
      return (series - series.min()) / (series.max() - series.min())

  mergedDF5['Stock_norm'] = normalize(mergedDF5['Open'])
  mergedDF5['SP500_norm'] = normalize(mergedDF5['Close'])

  # Plotting
  plt.figure(figsize=(14, 6))
  plt.plot(mergedDF5['Date'], mergedDF5['Stock_norm'], label=f'{name} (Normalized)', color='blue')
  plt.plot(mergedDF5['Date'], mergedDF5['SP500_norm'], label='S&P 500 (Normalized)', color='gray')
  plt.title(f'{name} vs S&P 500 (Normalized)')
  plt.xlabel('Date')
  plt.ylabel('Normalized Price')
  plt.legend()
  plt.grid(True)
  plt.tight_layout()
  plt.show()

  # Correlation
  correlation = mergedDF5['Stock_norm'].corr(mergedDF5['SP500_norm'])
  print(f"Correlation between {name} and S&P 500: {correlation:.3f}")

# Comparing Apple to S&P 500
compareToSP500(appleDF, "Apple")

# Comparing Intel to S&P 500
compareToSP500(intelDF, "Intel")

# Comparing Microsoft to S&P 500
compareToSP500(msftDF, "Microsoft")

"""## Comparison of company correlations with S&P500
1. Microsoft (0.962)
2. Apple (0.948)
3. Intel (0.730)

A higher correlation means that the company is closely correlated with the S&P 500. This suggests that a company with a higher correlation is very market-sensitive and less likely to act independently.

A lower (but still positive) correlation suggests that the stock is more independent and may be affected more by company-specific events. This could mean more more volatility or less predictability based on the overall market.

## Correlations of Companies with each other

## Company Opening Correlations
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

def compare_company_prices_multi(df_dict, price_types=['Open']):
    merged_df = None

    for company, df in df_dict.items():
        temp_cols = ['Date'] + price_types
        temp_df = df[temp_cols].copy()
        temp_df = temp_df.rename(columns={ptype: f"{company}_{ptype}" for ptype in price_types})

        if merged_df is None:
            merged_df = temp_df
        else:
            merged_df = pd.merge(merged_df, temp_df, on='Date', how='outer')  # Changed to outer join

    merged_df.sort_values('Date', inplace=True)
    merged_df.interpolate(method='linear', inplace=True)  # Fill in missing values
    merged_df.dropna(inplace=True)

    price_columns = [col for col in merged_df.columns if col != 'Date']
    return merged_df[price_columns].corr()

df_dict = {
    'Apple': appleDF,
    'Intel': intelDF,
    'Microsoft': msftDF,
    'IBM': ibmDF
}

correlation_open = compare_company_prices_multi(df_dict, price_types=['Open'])
print(correlation_open)

plt.figure(figsize=(10, 6))
sns.heatmap(correlation_open, annot=True, cmap='coolwarm', vmin=-1, vmax=1)
plt.title('Correlation Matrix of Open Prices')
plt.tight_layout()
plt.show()

"""### Comparison of Company Opens

1. Apple & Microsoft â€” 0.970
2. Intel & IBM â€” 0.770
3. Microsoft & IBM â€” 0.745
4. Apple & IBM â€” 0.730
5. Microsoft & Intel â€” 0.704
6. Apple & Intel â€” 0.687

All four companies show strong positive correlations in their opening prices, meaning their stocks tend to begin the trading day moving in similar directions. Apple and Microsoft are the most closely aligned, with the highest correlation, indicating nearly identical opening price behavior. Intel and IBM also exhibit a strong connection, followed closely by Microsoft and IBM. Apple and Intel have the weakest correlation in the group, though it remains significant. These results suggest that while all four companies are influenced by common market trends, Apple and Microsoft are the most tightly linked at market open.

## Company Closing Correlations
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Compare Close across multiple companies to compute pairwise correlations
def compare_company_prices_outer(df_dict, price_type='Close'):
    merged_df = None

    for company, df in df_dict.items():
        temp_df = df[['Date', price_type]].copy()
        temp_df = temp_df.rename(columns={price_type: f"{company}_{price_type}"})
        if merged_df is None:
            merged_df = temp_df
        else:
            merged_df = pd.merge(merged_df, temp_df, on='Date', how='outer')

    merged_df.sort_values('Date', inplace=True)
    merged_df.interpolate(method='linear', inplace=True)
    merged_df.dropna(inplace=True)

    return merged_df.drop(columns='Date').corr()

df_dict = {
    'Apple': appleDF,
    'Intel': intelDF,
    'Microsoft': msftDF,
    'IBM': ibmDF
}

correlation_matrix = compare_company_prices_outer(df_dict, price_type='Close')
print(correlation_matrix)

plt.figure(figsize=(10, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)
plt.title('Correlation Matrix of Close Prices')
plt.tight_layout()
plt.show()

"""### Comparison of Company Closes

1. Apple & Microsoft â€” 0.970
2. Intel & IBM â€” 0.769
3. Microsoft & IBM â€” 0.745
4. Apple & IBM â€” 0.729
5. Microsoft & Intel â€” 0.704
6. Apple & Intel â€” 0.683

All four companies demonstrate strong positive correlations in their closing prices, indicating that their stocks tend to move in the same direction by the end of the trading day. Apple and Microsoft once again have the strongest correlation, reflecting closely aligned price behavior throughout the day. Intel and IBM show a strong connection as well, followed by Microsoft and IBM. Apple and Intel have the weakest closing correlation in the group, though it remains substantial. These findings reinforce the idea that while all companies are shaped by broader market forces, Apple and Microsoft maintain the tightest relationship in how their stock prices close.

## Correlations of Companies with each other (Lagged)
"""

import pandas as pd

def lagged_correlation(df1, df2, days=30):
    df1 = df1[['Date', 'Open']].copy().sort_values('Date')
    df2 = df2[['Date', 'Open']].copy().sort_values('Date')

    df2 = df2.copy()
    df2['Open'] = df2['Open'].shift(days)

    # Merge on Date
    merged = pd.merge(df1, df2, on='Date', suffixes=('_df1', '_df2'))
    merged.dropna(inplace=True)

    if not merged.empty:
        return merged['Open_df1'].corr(merged['Open_df2'])
    else:
        return None

companies = {
    'Apple': appleDF,
    'Intel': intelDF,
    'Microsoft': msftDF,
    'IBM': ibmDF
}

lagged_matrix = pd.DataFrame(index=companies.keys(), columns=companies.keys())

for base_name, base_df in companies.items():
    for lagged_name, lagged_df in companies.items():
        try:
            corr = lagged_correlation(base_df, lagged_df, days=30)
            lagged_matrix.loc[base_name, lagged_name] = round(corr, 4) if corr is not None else "N/A"
        except Exception as e:
            lagged_matrix.loc[base_name, lagged_name] = f"Err"

print("30-Day Lagged Correlation Matrix (Column company leads):")
display(lagged_matrix)

import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

lagged_matrix_numeric = lagged_matrix.replace("N/A", np.nan)
lagged_matrix_numeric = lagged_matrix_numeric.infer_objects(copy=False).astype(float)

plt.figure(figsize=(8, 6))
sns.heatmap(lagged_matrix_numeric, annot=True, cmap='coolwarm', vmin=0.5, vmax=1.0)
plt.title('30-Day Lagged Correlation Heatmap (Column Leads)')
plt.xlabel('Leading Company (30 Days Earlier)')
plt.ylabel('Following Company')
plt.tight_layout()
plt.show()

"""#### The 30-day lagged correlation analysis reveals strong temporal relationships between several major tech stocks, indicating how the movement of one company's stock may influence another over time. Apple and Microsoft exhibit the strongest mutual lagged correlation, with values of 0.9699 and 0.9657 respectively, suggesting their stock prices tend to move closely together even with a one-month delay. IBM also shows a moderate delayed influence on Microsoft (0.7138) and vice versa (0.7050), highlighting some interdependence between these two companies. In contrast, most of the lagged correlations involving Intel are unavailable, likely due to differences in available data ranges or gaps in overlapping timeframes. Overall, the findings suggest that Apple and Microsoft are the most closely linked in both immediate and delayed stock movement, while IBM maintains moderate influence and Intel may behave more independently or requires further data cleaning to evaluate effectively.

## Trying a longer lag
"""

# Trying 60 days
lag_60_matrix = pd.DataFrame(index=companies.keys(), columns=companies.keys())

for base_name, base_df in companies.items():
    for lagged_name, lagged_df in companies.items():
        try:
            corr = lagged_correlation(base_df, lagged_df, days=60)
            lag_60_matrix.loc[base_name, lagged_name] = round(corr, 4) if corr is not None else "N/A"
        except Exception as e:
            lag_60_matrix.loc[base_name, lagged_name] = "Err"

# Prepare for plotting
lag_60_numeric = lag_60_matrix.replace("N/A", np.nan)
lag_60_numeric = lag_60_numeric.infer_objects(copy=False).astype(float)

print("60-Day Lagged Correlation Matrix (Column company leads):")
display(lag_60_numeric)

# Plot
plt.figure(figsize=(8, 6))
sns.heatmap(lag_60_numeric, annot=True, cmap='coolwarm', vmin=0.5, vmax=1.0)
plt.title('60-Day Lagged Correlation Heatmap (Column Leads)')
plt.xlabel('Leading Company (60 Days Earlier)')
plt.ylabel('Following Company')
plt.tight_layout()
plt.show()

"""#### The 60-day lagged correlation matrix supports earlier findings from the 30-day lag analysis. Apple and Microsoft continue to exhibit the strongest mutual lagged correlation, with values above 0.96, indicating sustained influence on each otherâ€™s stock performance over two months. IBM shows moderate influence on Microsoft (0.7129) and vice versa (0.6988), consistent with their roles in similar enterprise technology markets. Intel remains underrepresented in the matrix due to data limitations, highlighting a need for further preprocessing or alignment. Overall, the similarity in patterns between the 30-day and 60-day lags suggests that most stock movements among these companies are influenced within the first month, with diminishing correlation beyond that window.

## Trying a shorter lag
"""

lag_14_matrix = pd.DataFrame(index=companies.keys(), columns=companies.keys())

for base_name, base_df in companies.items():
    for lagged_name, lagged_df in companies.items():
        try:
            corr = lagged_correlation(base_df, lagged_df, days=14)
            lag_14_matrix.loc[base_name, lagged_name] = round(corr, 4) if corr is not None else "N/A"
        except Exception as e:
            lag_14_matrix.loc[base_name, lagged_name] = "Err"

lag_14_numeric = lag_14_matrix.replace("N/A", np.nan)
lag_14_numeric = lag_14_numeric.infer_objects(copy=False).astype(float)

print("14-Day Lagged Correlation Matrix (Column company leads):")
display(lag_14_numeric)

plt.figure(figsize=(8, 6))
sns.heatmap(lag_14_numeric, annot=True, cmap='coolwarm', vmin=0.5, vmax=1.0)
plt.title('14-Day Lagged Correlation Heatmap (Column Leads)')
plt.xlabel('Leading Company (14 Days Earlier)')
plt.ylabel('Following Company')
plt.tight_layout()
plt.show()

"""#### The 14-day lagged correlation analysis reveals even stronger relationships between key tech companies than those observed at longer time intervals. Apple and Microsoft maintain the highest mutual influence, with lagged correlations of 0.9706 and 0.9683 respectively, indicating that shifts in one company's stock price are closely mirrored by the other within just two weeks. IBM also demonstrates a consistent delayed relationship with Microsoft, with correlations around 0.71 in both directions. These values are slightly higher than those from the 30- and 60-day lag analyses, suggesting that inter-company stock movements are most responsive within a shorter time frame. Once again, Intel's correlations are missing, likely due to misaligned or insufficient overlapping data after the lag shift. Overall, the results support the idea that the stock prices of Apple, Microsoft, and IBM are closely intertwined and that market reactions tend to manifest within 14 days.

## Overall Summary

The lagged correlation analysis examined how the stock prices of Apple, Microsoft, Intel, and IBM respond to each other over time, using 14-day, 30-day, and 60-day lags. Across all intervals, Apple and Microsoft consistently showed the strongest mutual lagged correlations, with values exceeding 0.96, indicating a tight and responsive relationship between their stock movements. IBM also demonstrated moderate delayed influence on Microsoft, with correlations above 0.70 at each lag. Notably, the correlations were strongest at the 14-day lag and gradually declined at 30 and 60 days, suggesting that the most significant inter-company influences occur within a two-week window. Intelâ€™s lagged correlations were consistently unavailable, likely due to data alignment issues following the lag shift. Overall, the analysis highlights how closely certain tech stocks track each other over short time horizons, offering insight into the timing and strength of market responses within the sector.

# 3) Predictive Modeling

## Model Building (Training Phase)
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.ensemble import VotingClassifier
import ta

# --- Labeling function with 0.5% threshold ---
def generate_labels(df, column='Close', days_ahead=5, threshold=0.005):
    df['FuturePrice'] = df[column].shift(-days_ahead)
    df['Return'] = (df['FuturePrice'] - df[column]) / df[column]
    df['Action'] = df['Return'].apply(lambda x: 1 if x > threshold else (-1 if x < -threshold else 0))
    return df

# --- Feature engineering with volume features ---
def generate_features(df):
    df['Close_Lag1'] = df['Close'].shift(1)
    df['Close_Lag2'] = df['Close'].shift(2)
    df['MA5'] = df['Close'].rolling(window=5).mean()
    df['MA10'] = df['Close'].rolling(window=10).mean()
    df['Momentum_5'] = df['Close'] - df['Close'].shift(5)
    df['Momentum_10'] = df['Close'] - df['Close'].shift(10)
    df['Daily_Return'] = df['Close'].pct_change()
    df['Volume_Lag1'] = df['Volume'].shift(1)
    df['OBV'] = ta.volume.OnBalanceVolumeIndicator(close=df['Close'], volume=df['Volume']).on_balance_volume()
    return df

# --- Model training ---
def build_model(df):
    df['Date'] = pd.to_datetime(df['Date'])
    df = generate_labels(df)
    df = generate_features(df)
    df.replace([np.inf, -np.inf], np.nan, inplace=True)
    df.dropna(inplace=True)

    feature_cols = [
        'Close_Lag1', 'Close_Lag2', 'MA5', 'MA10',
        'Momentum_5', 'Momentum_10', 'Daily_Return',
        'Volume_Lag1', 'OBV'
    ]
    X = df[feature_cols]
    y = df['Action']

    label_map = {-1: 0, 0: 1, 1: 2}
    reverse_map = {v: k for k, v in label_map.items()}
    y_mapped = y.map(label_map)

    X_train, X_test, y_train, y_test = train_test_split(X, y_mapped, test_size=0.2, shuffle=False)

    logistic = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)
    xgb_clf = XGBClassifier(
        objective='multi:softmax',
        num_class=3,
        eval_metric='mlogloss',
        use_label_encoder=False,
        random_state=42
    )

    ensemble = VotingClassifier(
        estimators=[('logistic', logistic), ('xgb', xgb_clf)],
        voting='soft'
    )
    ensemble.fit(X_train, y_train)
    return ensemble, X_test, y_test, reverse_map

"""## Model Testing (Evaluation Phase)"""

from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

def test_model(model, X_test, y_test, reverse_map, stock_name):
    y_pred = model.predict(X_test)

    y_test_original = y_test.map(reverse_map)
    y_pred_original = pd.Series(y_pred).map(reverse_map)

    cm = confusion_matrix(y_test_original, y_pred_original, labels=[-1, 0, 1])
    labels = ['Sell (-1)', 'Hold (0)', 'Buy (1)']

    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.title(f'{stock_name} â€” Ensemble Confusion Matrix')
    plt.tight_layout()
    plt.show()

    print(f"\nClassification Report for {stock_name}:")
    print(classification_report(y_test_original, y_pred_original, target_names=labels))

# --- Load and evaluate all datasets ---
datasets = {
    'Apple': pd.read_csv('/content/drive/MyDrive/AI4ALL Project Datasets/AAPL.csv'),
    'Microsoft': pd.read_csv('/content/drive/MyDrive/AI4ALL Project Datasets/MSFT.csv'),
    'Intel': pd.read_csv('/content/drive/MyDrive/AI4ALL Project Datasets/INTC.csv'),
    'IBM': pd.read_csv('/content/drive/MyDrive/AI4ALL Project Datasets/IBM.csv')
}

for name, df in datasets.items():
    model, X_test, y_test, reverse_map = build_model(df)
    test_model(model, X_test, y_test, reverse_map, name)

"""# 4) Class Performance Across Stocks"""

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# Manually input your metrics
metrics_data = {
    'Stock': ['Apple'] * 3 + ['Microsoft'] * 3 + ['Intel'] * 3 + ['IBM'] * 3,
    'Class': ['Sell (-1)', 'Hold (0)', 'Buy (1)'] * 4,
    'Precision': [0.38, 0.14, 0.53, 0.35, 0.11, 0.68, 0.40, 0.05, 0.46, 0.40, 0.21, 0.48],
    'Recall': [0.06, 0.04, 0.92, 0.78, 0.16, 0.05, 0.77, 0.01, 0.19, 0.54, 0.17, 0.35],
    'F1-Score': [0.10, 0.06, 0.67, 0.48, 0.13, 0.09, 0.53, 0.02, 0.27, 0.46, 0.19, 0.40]
}

df_metrics = pd.DataFrame(metrics_data)

# Reshape the DataFrame for seaborn
df_melted = df_metrics.melt(id_vars=['Stock', 'Class'],
                            value_vars=['Precision', 'Recall', 'F1-Score'],
                            var_name='Metric', value_name='Score')

# Plot using catplot with bar kind
g = sns.catplot(
    data=df_melted,
    kind='bar',
    x='Class',
    y='Score',
    hue='Stock',
    col='Metric',
    height=4,
    aspect=1.2,
    errorbar=None
)

g.fig.subplots_adjust(top=0.85)
g.fig.suptitle('Model Performance Metrics by Class Across Stocks', fontsize=16)

plt.show()

"""The bar chart visualization reveals significant differences in model performance across stocks and classes.

For the "Buy (1)" class, Apple achieves the highest precision (0.53) and an exceptionally high recall (0.92), indicating the model is highly sensitive to buy signals for Apple but may overpredict them.

In contrast, Microsoftâ€™s model shows high precision for "Buy" (0.68) but extremely low recall (0.05), meaning it predicts buys accurately but rarely makes those predictions.

Intel and IBM display more balanced yet moderate performance, with precision and recall in the 0.4â€“0.5 range for the "Sell" and "Buy" classes, while all models perform poorly on the "Hold (0)" class, showing universally low precision, recall, and F1-scores.

These results suggest the model struggles to distinguish hold signals, potentially due to their subtler patterns, and performs best when identifying clear upward or downward trends.
"""
